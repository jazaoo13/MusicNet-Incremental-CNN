{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uR4ViAjgasw1",
        "4DBblPCjZhla"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Libraries"
      ],
      "metadata": {
        "id": "uR4ViAjgasw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install scikit-learn\n",
        "!pip install numpy"
      ],
      "metadata": {
        "id": "sQXlgRm2ZQSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Code adapted to run in batches and generate outputs for all classes available in the complete dataset\n"
      ],
      "metadata": {
        "id": "4DBblPCjZhla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this version I used the separation contained in the Training/Validation Musicnet itself. Each batch is validated with the data contained in validation_musics... This version is adapted to work here at Colab, it was a test to check the processing speed."
      ],
      "metadata": {
        "id": "BH8g9YvlZtPg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLmtl75BBSqs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from datetime import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "# ============================\n",
        "# Seed for reproducibility\n",
        "# ============================\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "# Paths for training and validation\n",
        "processed_path = \"/content/Processed_Musics\"       # Traning content path\n",
        "validation_path = \"/content/Validation_Musics\"       # Validation content path\n",
        "\n",
        "# Set up paths for logs and checkpoints\n",
        "output_dir = os.path.join(\"/content\", \"Logs\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "log_file_name = os.path.join(output_dir, f\"incremental_training_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\")\n",
        "\n",
        "# ============================\n",
        "# Dataset subset for incremental training\n",
        "# ============================\n",
        "class ProcessedDatasetSubset(Dataset):\n",
        "    \"\"\"\n",
        "    Loads a subset of .pt files starting from a given index.\n",
        "    All file data is loaded during initialization.\n",
        "    \"\"\"\n",
        "    def __init__(self, data_dir, start_file=0, max_files=None):\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.file_names = []  # To store the names of the processed files\n",
        "        files = sorted([f for f in os.listdir(data_dir) if f.endswith(\".pt\")])\n",
        "        if max_files is not None:\n",
        "            files = files[start_file:start_file+max_files]\n",
        "        self.file_names = files  # Save filenames for logging\n",
        "        for file in files:\n",
        "            file_path = os.path.join(data_dir, file)\n",
        "            data_loaded = torch.load(file_path, weights_only=True)\n",
        "            mel_spec_segments = data_loaded[\"mel_spec_segments\"]\n",
        "            labels = data_loaded[\"y\"]\n",
        "            for segment, label in zip(mel_spec_segments, labels):\n",
        "                if segment.shape[0] != 128:\n",
        "                    raise ValueError(f\"Invalid spectrogram found: {segment.shape}\")\n",
        "                self.data.append(segment.clone().detach().float())\n",
        "                self.labels.append(int(label))\n",
        "        unique_classes = sorted(set(self.labels))\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
        "        self.idx_to_class = {idx: cls for cls, idx in self.class_to_idx.items()}\n",
        "        self.mapped_labels = [self.class_to_idx[label] for label in self.labels]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.mapped_labels[idx]\n",
        "\n",
        "# ============================\n",
        "# Dataset for validation\n",
        "# ============================\n",
        "class ProcessedDatasetValidation(Dataset):\n",
        "    \"\"\"\n",
        "    Loads all data from the validation folder during initialization.\n",
        "    \"\"\"\n",
        "    def __init__(self, data_dir, max_files=None):\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        files = sorted([f for f in os.listdir(data_dir) if f.endswith(\".pt\")])\n",
        "        if max_files is not None:\n",
        "            files = files[:max_files]\n",
        "        for file in files:\n",
        "            file_path = os.path.join(data_dir, file)\n",
        "            data_loaded = torch.load(file_path, weights_only=True)\n",
        "            mel_spec_segments = data_loaded[\"mel_spec_segments\"]\n",
        "            labels = data_loaded[\"y\"]\n",
        "            for segment, label in zip(mel_spec_segments, labels):\n",
        "                if segment.shape[0] != 128:\n",
        "                    raise ValueError(f\"Invalid spectrogram found:: {segment.shape}\")\n",
        "                self.data.append(segment.clone().detach().float())\n",
        "                self.labels.append(int(label))\n",
        "        unique_classes = sorted(set(self.labels))\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
        "        self.idx_to_class = {idx: cls for cls, idx in self.class_to_idx.items()}\n",
        "        self.mapped_labels = [self.class_to_idx[label] for label in self.labels]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.mapped_labels[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    mel_specs = [item[0] for item in batch]\n",
        "    labels = torch.tensor([item[1] for item in batch], dtype=torch.long)\n",
        "    return mel_specs, labels\n",
        "\n",
        "def get_total_num_classes(data_dir, max_files=None):\n",
        "    unique_labels = set()\n",
        "    files = sorted([f for f in os.listdir(data_dir) if f.endswith(\".pt\")])\n",
        "    if max_files is not None:\n",
        "        files = files[:max_files]\n",
        "    for file in files:\n",
        "        file_path = os.path.join(data_dir, file)\n",
        "        data_loaded = torch.load(file_path, weights_only=True)\n",
        "        # Convert each label to an integer\n",
        "        labels = [int(l) for l in data_loaded[\"y\"]]\n",
        "        unique_labels.update(set(labels))\n",
        "    unique_labels = sorted(unique_labels)\n",
        "    return len(unique_labels), unique_labels\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================\n",
        "# CNN Model\n",
        "# ============================\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1))\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, x_list):\n",
        "        batch_outputs = []\n",
        "        for x in x_list:\n",
        "            x = x.unsqueeze(0).unsqueeze(0)  # from (128, L) to (1, 1, 128, L)\n",
        "            x = F.relu(self.conv1(x))\n",
        "            x = self.pool(x)\n",
        "            x = F.relu(self.conv2(x))\n",
        "            x = self.pool(x)\n",
        "            x = F.relu(self.conv3(x))\n",
        "            x = self.global_pool(x)  # (1, 128, 1, 1)\n",
        "            x = x.view(x.size(0), -1)  # Flatten to (1, 128)\n",
        "            x = self.dropout(x)\n",
        "            x = self.fc2(x)\n",
        "            batch_outputs.append(x)\n",
        "        return torch.cat(batch_outputs, dim=0)\n",
        "\n",
        "# ============================\n",
        "# Incremental training function with validation and early stopping\n",
        "# ============================\n",
        "def train_incremental(model, optimizer, criterion, train_loader, val_loader, device, num_epochs, logger):\n",
        "    model.train()\n",
        "    early_stop_threshold = 0.80  # Set F1 Score to Stop\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        all_train_labels = []\n",
        "        all_train_preds = []\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = [inp.to(device).float() for inp in inputs]\n",
        "            labels = labels.to(device).long()\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            all_train_labels.extend(labels.cpu().numpy())\n",
        "            all_train_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        train_f1 = f1_score(all_train_labels, all_train_preds, average='weighted', zero_division=0)\n",
        "        train_precision = precision_score(all_train_labels, all_train_preds, average='weighted', zero_division=0)\n",
        "        train_recall = recall_score(all_train_labels, all_train_preds, average='weighted', zero_division=0)\n",
        "\n",
        "        # Check if early stopping criterion has been met\n",
        "        if train_f1 >= early_stop_threshold:\n",
        "            logger(f\"EARLY STOPPING ACTIVATED! Train F1 = {train_f1:.4f} surpass {early_stop_threshold:.4f} at epoch {epoch+1}.\")\n",
        "            break\n",
        "\n",
        "        # Validação (modo avaliação)\n",
        "        model.eval()\n",
        "        all_val_labels = []\n",
        "        all_val_preds = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs = [inp.to(device).float() for inp in inputs]\n",
        "                labels = labels.to(device).long()\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                all_val_labels.extend(labels.cpu().numpy())\n",
        "                all_val_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "        val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted', zero_division=0)\n",
        "        val_precision = precision_score(all_val_labels, all_val_preds, average='weighted', zero_division=0)\n",
        "        val_recall = recall_score(all_val_labels, all_val_preds, average='weighted', zero_division=0)\n",
        "\n",
        "        logger(f\"Epoch {epoch+1}/{num_epochs}: Train Loss = {avg_loss:.4f}, \"\n",
        "               f\"Train F1 = {train_f1:.4f}, P = {train_precision:.4f}, R = {train_recall:.4f} || \"\n",
        "               f\"Val F1 = {val_f1:.4f}, P = {val_precision:.4f}, R = {val_recall:.4f}\")\n",
        "\n",
        "        model.train()  # Return to training mode after validation\n",
        "\n",
        "    return model, optimizer\n",
        "\n",
        "\n",
        "# ============================\n",
        "# Incremental training main function\n",
        "# ============================\n",
        "def main():\n",
        "    # Incremental training parameters:\n",
        "    files_per_batch = 25       # Number of files (songs) per batch\n",
        "    num_epochs_per_batch = 10  # Batch training epochs\n",
        "    num_classes, classes_list = get_total_num_classes(processed_path)\n",
        "    print(f\"Total de classes no dataset: {num_classes}\")\n",
        "    print(f\"Classes: {classes_list}\")\n",
        "    # List of files available in the training folder\n",
        "    all_train_files = sorted([f for f in os.listdir(processed_path) if f.endswith(\".pt\")])\n",
        "    total_train_files = len(all_train_files)\n",
        "\n",
        "    # Load the validation dataset (you can limit it if you wish)\n",
        "    validation_dataset = ProcessedDatasetValidation(validation_path, max_files=None)\n",
        "    val_loader = DataLoader(validation_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    with open(log_file_name, \"w\") as log_file:\n",
        "        def log_message(message):\n",
        "            print(message)\n",
        "            log_file.write(message + \"\\n\")\n",
        "            log_file.flush()\n",
        "\n",
        "        log_message(f\"Total training files in the directory: {total_train_files}\")\n",
        "        log_message(f\"Starting incremental training with batches of {files_per_batch} files and {num_epochs_per_batch} epochs per batch.\")\n",
        "\n",
        "        start_file = 0\n",
        "\n",
        "        # Initialize the model using the classes from the first batch\n",
        "        dataset_subset = ProcessedDatasetSubset(processed_path, start_file=start_file, max_files=files_per_batch)\n",
        "        # Log: display filenames from the first batch\n",
        "        log_message(f\"Current batch (files): {dataset_subset.file_names}\")\n",
        "        model = CNN(input_shape=(128, 128), num_classes=num_classes).to(device)\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Loop incremental: treina lote a lote\n",
        "        while start_file < total_train_files:\n",
        "            log_message(f\"Training batch files: {start_file} until {min(start_file+files_per_batch, total_train_files)}\")\n",
        "            # Create dataset for the current batch\n",
        "            dataset_subset = ProcessedDatasetSubset(processed_path, start_file=start_file, max_files=files_per_batch)\n",
        "            # Print filenames in this batch\n",
        "            log_message(f\"Files at this batch: {dataset_subset.file_names}\")\n",
        "            train_loader = DataLoader(dataset_subset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "            # Train the model on this batch and evaluate using the fixed validation set\n",
        "            model, optimizer = train_incremental(model, optimizer, criterion, train_loader, val_loader, device, num_epochs_per_batch, log_message)\n",
        "\n",
        "            # Save a checkpoint after training this batch\n",
        "            checkpoint_path = os.path.join(output_dir, f\"checkpoint_{start_file}_{start_file+files_per_batch}.pt\")\n",
        "            torch.save({\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "                \"last_file_index\": start_file+files_per_batch,\n",
        "            }, checkpoint_path)\n",
        "            log_message(f\"Checkpoint salvo em: {checkpoint_path}\")\n",
        "\n",
        "            # Move to the next batch\n",
        "            start_file += files_per_batch\n",
        "\n",
        "        log_message(\"Incremental training completed.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "eJVapVL3aqS-"
      }
    }
  ]
}